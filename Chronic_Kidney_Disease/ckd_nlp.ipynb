{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "604d2b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\tonim\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\tonim\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\tonim\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\tonim\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           patient_uuid                 document_reference_id  \\\n",
      "0  16ec7045-4e43-cb9e-0445-f43732e3c63c  442748b2-7618-75f6-3640-026ca9100895   \n",
      "1  16ec7045-4e43-cb9e-0445-f43732e3c63c  46c4500c-0955-39f7-35e5-dba7ac84b321   \n",
      "2  16ec7045-4e43-cb9e-0445-f43732e3c63c  7ca96006-8459-01bf-f10f-512bc23d3332   \n",
      "3  16ec7045-4e43-cb9e-0445-f43732e3c63c  33262ab9-30a4-518d-cec9-5a325a937318   \n",
      "4  16ec7045-4e43-cb9e-0445-f43732e3c63c  391d6089-7983-c098-678b-ed475e2b7d1e   \n",
      "\n",
      "   title                                          note_text  \\\n",
      "0    NaN  \\n2019-06-08\\n\\n# Chief Complaint\\n- Frequent ...   \n",
      "1    NaN  \\n2019-06-05\\n\\n# Chief Complaint\\n- Frequent ...   \n",
      "2    NaN  \\n2019-06-16\\n\\n# Chief Complaint\\n- Frequent ...   \n",
      "3    NaN  \\n2019-06-23\\n\\n# Chief Complaint\\n- Frequent ...   \n",
      "4    NaN  \\n2019-06-30\\n\\n# Chief Complaint\\n- Frequent ...   \n",
      "\n",
      "                                        cleaned_text  \n",
      "0  2019 06 08 chief complaint frequent urination ...  \n",
      "1  2019 06 05 chief complaint frequent urination ...  \n",
      "2  2019 06 16 chief complaint frequent urination ...  \n",
      "3  2019 06 23 chief complaint frequent urination ...  \n",
      "4  2019 06 30 chief complaint frequent urination ...  \n",
      "                           patient_uuid  egfr ckd_stage\n",
      "0  16ec7045-4e43-cb9e-0445-f43732e3c63c  None      None\n",
      "1  16ec7045-4e43-cb9e-0445-f43732e3c63c  None      None\n",
      "2  16ec7045-4e43-cb9e-0445-f43732e3c63c  None      None\n",
      "3  16ec7045-4e43-cb9e-0445-f43732e3c63c  None      None\n",
      "4  16ec7045-4e43-cb9e-0445-f43732e3c63c  None      None\n",
      "                           patient_uuid  \\\n",
      "0  16ec7045-4e43-cb9e-0445-f43732e3c63c   \n",
      "1  16ec7045-4e43-cb9e-0445-f43732e3c63c   \n",
      "2  16ec7045-4e43-cb9e-0445-f43732e3c63c   \n",
      "3  16ec7045-4e43-cb9e-0445-f43732e3c63c   \n",
      "4  16ec7045-4e43-cb9e-0445-f43732e3c63c   \n",
      "\n",
      "                                           note_text  ckd_mentions  \\\n",
      "0  \\n2019-06-08\\n\\n# Chief Complaint\\n- Frequent ...          True   \n",
      "1  \\n2019-06-05\\n\\n# Chief Complaint\\n- Frequent ...          True   \n",
      "2  \\n2019-06-16\\n\\n# Chief Complaint\\n- Frequent ...          True   \n",
      "3  \\n2019-06-23\\n\\n# Chief Complaint\\n- Frequent ...          True   \n",
      "4  \\n2019-06-30\\n\\n# Chief Complaint\\n- Frequent ...          True   \n",
      "\n",
      "   ckd_symptoms  ckd_with_symptoms  egfr creatinine  \n",
      "0          True               True  None       None  \n",
      "1          True               True  None       None  \n",
      "2          True               True  None       None  \n",
      "3          True               True  None       None  \n",
      "4          True               True  None       None  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "# -------------------------\n",
    "# NLTK setup\n",
    "# -------------------------\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# -------------------------\n",
    "# Load CSV\n",
    "# -------------------------\n",
    "df = pd.read_csv(\"D:\\\\document_references_fhir_raw.csv\")  # adjust filename\n",
    "\n",
    "# Assume CSV already has 'patient_id' and 'note_text'\n",
    "# -------------------------\n",
    "# NLP preprocessing\n",
    "# -------------------------\n",
    "def clean_text(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', ' ', text)  # keep numbers for labs\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [t for t in tokens if t not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "df['cleaned_text'] = df['note_text'].apply(clean_text)\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "# -------------------------\n",
    "# CKD stage assignment function\n",
    "# -------------------------\n",
    "def assign_ckd_stage(egfr):\n",
    "    if egfr is None:\n",
    "        return None\n",
    "    elif egfr >= 90:\n",
    "        return 1\n",
    "    elif 60 <= egfr < 90:\n",
    "        return 2\n",
    "    elif 45 <= egfr < 60:\n",
    "        return '3a'\n",
    "    elif 30 <= egfr < 45:\n",
    "        return '3b'\n",
    "    elif 15 <= egfr < 30:\n",
    "        return 4\n",
    "    elif egfr < 15:\n",
    "        return 5\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# CKD keywords and symptoms\n",
    "# -------------------------\n",
    "ckd_terms = ['chronic kidney disease', 'ckd', 'egfr', 'creatinine', 'renal insufficiency', 'kidney failure', 'dialysis']\n",
    "ckd_symptoms = ['fatigue', 'swelling', 'edema', 'nausea', 'vomiting', 'shortness of breath', 'high blood pressure', 'hypertension']\n",
    "\n",
    "# Vectorized search using regex for speed\n",
    "df['ckd_mentions'] = df['cleaned_text'].str.contains('|'.join(ckd_terms), case=False, regex=True)\n",
    "df['ckd_symptoms'] = df['cleaned_text'].str.contains('|'.join(ckd_symptoms), case=False, regex=True)\n",
    "df['ckd_with_symptoms'] = df['ckd_mentions'] & df['ckd_symptoms']\n",
    "\n",
    "\n",
    "\n",
    "# Save results\n",
    "df.to_csv(\"ckd_nlp_results_with_staging.csv\", index=False)\n",
    "\n",
    "# -------------------------\n",
    "# Extract numeric lab values\n",
    "# -------------------------\n",
    "def extract_egfr(text):\n",
    "    match = re.search(r'\\b(eGFR|egfr)\\s*[:=]?\\s*(\\d+)', str(text), re.IGNORECASE)\n",
    "    return int(match.group(2)) if match else None\n",
    "\n",
    "def extract_creatinine(text):\n",
    "    match = re.search(r'\\b(creatinine|cr)\\s*[:=]?\\s*(\\d+(\\.\\d+)?)', str(text), re.IGNORECASE)\n",
    "    return float(match.group(2)) if match else None\n",
    "\n",
    "df['egfr'] = df['note_text'].apply(extract_egfr)\n",
    "df['creatinine'] = df['note_text'].apply(extract_creatinine)\n",
    "\n",
    "# Assign CKD stage based on eGFR\n",
    "df['ckd_stage'] = df['egfr'].apply(assign_ckd_stage)\n",
    "\n",
    "# Preview\n",
    "print(df[['patient_uuid', 'egfr', 'ckd_stage']].head())\n",
    "\n",
    "# -------------------------\n",
    "# Select relevant columns\n",
    "# -------------------------\n",
    "output_w_notes_df = df[['patient_uuid', 'note_text', 'ckd_mentions', 'ckd_symptoms', 'ckd_with_symptoms', 'egfr', 'creatinine']]\n",
    "output_no_notes_df = df[['patient_uuid', 'ckd_mentions', 'ckd_symptoms', 'ckd_with_symptoms', 'egfr', 'creatinine']]\n",
    "\n",
    "# Save results\n",
    "output_w_notes_df.to_csv(\"ckd_nlp_results_with_labs.csv\", index=False)\n",
    "output_no_notes_df.to_csv(\"ckd_nlp_results_no_notes.csv\", index=False)\n",
    "\n",
    "# Preview\n",
    "print(output_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e42f58c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Users\\\\tonim/nltk_data', 'C:\\\\Users\\\\tonim\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\nltk_data', 'C:\\\\Users\\\\tonim\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\share\\\\nltk_data', 'C:\\\\Users\\\\tonim\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\lib\\\\nltk_data', 'C:\\\\Users\\\\tonim\\\\AppData\\\\Roaming\\\\nltk_data', 'C:\\\\nltk_data', 'D:\\\\nltk_data', 'E:\\\\nltk_data']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "print(nltk.data.path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.13",
   "language": "python",
   "name": "python313"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
